{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPhV5cSEBtGKN8HqICx0Ec",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rswijesena/AI/blob/main/OpenAI_Intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3ptCfdOZU_4_"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip install panda\n",
        "!pip install pip install langchain\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "SZFw8PMbgGP2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openAIKey=\"\""
      ],
      "metadata": {
        "id": "TYQlBa-jw07a"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = openAIKey\n",
        "all_models = openai.models.list()\n",
        "list(all_models)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7wzgHDvPw-Uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(list(all_models))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ohTZSLDfxics"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=openAIKey)"
      ],
      "metadata": {
        "id": "0fjpr0Cl76Zh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"company assistant\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"who won the first cricket world cup?\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=1,\n",
        "  max_tokens=150,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "response.choices[0].message.content"
      ],
      "metadata": {
        "id": "9_W3k5fj5McE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain"
      ],
      "metadata": {
        "id": "PzHYCIwmJj9H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "developer_description = \"Roshan Wijsena is a integration developer at Boomi with 10 years of industry experince, he studied at UCD and he is in gravonder club, his grade is grade A\"\n",
        "\n"
      ],
      "metadata": {
        "id": "WfNim6hRMWOC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "prompt = f'''\n",
        "Please extract the following information from the given text and return it as a JSON object:\n",
        "\n",
        "name\n",
        "collage\n",
        "grades\n",
        "club\n",
        "\n",
        "This is the body of text to extract the information from:\n",
        "{developer_description}\n",
        "'''\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "X2zfTv2XgWSI",
        "outputId": "3369a69c-f5b0-4292-b663-9ddefac2cce3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\": \"Roshan Wijsena\",\n",
            "  \"college\": \"UCD\",\n",
            "  \"grades\": \"grade A\",\n",
            "  \"club\": \"gravonder club\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Calling function\n",
        "\n",
        "from openai import OpenAI\n",
        "import json\n",
        "\n",
        "# Example dummy function hard coded to return the same weather\n",
        "# In production, this could be your backend API or an external API\n",
        "def get_current_weather(location, unit=\"fahrenheit\"):\n",
        "    \"\"\"Get the current weather in a given location\"\"\"\n",
        "    if \"tokyo\" in location.lower():\n",
        "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})\n",
        "    elif \"san francisco\" in location.lower():\n",
        "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit})\n",
        "    elif \"paris\" in location.lower():\n",
        "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n",
        "    else:\n",
        "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n",
        "\n",
        "def run_conversation():\n",
        "    # Step 1: send the conversation and available functions to the model\n",
        "    messages = [{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco, Tokyo, and Paris?\"}]\n",
        "    tools = [\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"get_current_weather\",\n",
        "                \"description\": \"Get the current weather in a given location\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"location\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "                        },\n",
        "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
        "                    },\n",
        "                    \"required\": [\"location\"],\n",
        "                },\n",
        "            },\n",
        "        }\n",
        "    ]\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-0125\",\n",
        "        messages=messages,\n",
        "        tools=tools,\n",
        "        tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
        "    )\n",
        "    response_message = response.choices[0].message\n",
        "    tool_calls = response_message.tool_calls\n",
        "    # Step 2: check if the model wanted to call a function\n",
        "    if tool_calls:\n",
        "        # Step 3: call the function\n",
        "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
        "        available_functions = {\n",
        "            \"get_current_weather\": get_current_weather,\n",
        "        }  # only one function in this example, but you can have multiple\n",
        "        messages.append(response_message)  # extend conversation with assistant's reply\n",
        "        # Step 4: send the info for each function call and function response to the model\n",
        "        for tool_call in tool_calls:\n",
        "            function_name = tool_call.function.name\n",
        "            function_to_call = available_functions[function_name]\n",
        "            function_args = json.loads(tool_call.function.arguments)\n",
        "            function_response = function_to_call(\n",
        "                location=function_args.get(\"location\"),\n",
        "                unit=function_args.get(\"unit\"),\n",
        "            )\n",
        "            messages.append(\n",
        "                {\n",
        "                    \"tool_call_id\": tool_call.id,\n",
        "                    \"role\": \"tool\",\n",
        "                    \"name\": function_name,\n",
        "                    \"content\": function_response,\n",
        "                }\n",
        "            )  # extend conversation with function response\n",
        "        second_response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo-0125\",\n",
        "            messages=messages,\n",
        "        )  # get a new response from the model where it can see the function response\n",
        "        return second_response\n",
        "print(list(run_conversation()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWtR4EjI5j3w",
        "outputId": "d8995d97-45de-4996-f47d-a49e28495f42"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('id', 'chatcmpl-9OEXnMIjXIHRCykmjZKCbwLKh9UV9'), ('choices', [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The current weather in San Francisco is 72°F, in Tokyo it is 10°C, and in Paris it is 22°C.', role='assistant', function_call=None, tool_calls=None))]), ('created', 1715562807), ('model', 'gpt-3.5-turbo-0125'), ('object', 'chat.completion'), ('system_fingerprint', None), ('usage', CompletionUsage(completion_tokens=28, prompt_tokens=147, total_tokens=175))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advance Function calling"
      ],
      "metadata": {
        "id": "zTlsSEkGhSmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo-0125\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"When's the next flight from delhi to mumbai?\"\n",
        "        }\n",
        "    ],\n",
        ")\n",
        "response.choices[0].message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "TofsJkGahFAw",
        "outputId": "43ce3145-983e-421f-e330-78954623d908"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There are multiple flights from Delhi to Mumbai throughout the day. It is recommended to check with airlines or travel websites for the most up-to-date and accurate information on flight schedules.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function_description = [\n",
        "    {\n",
        "        \"name\": \"get_next_flight\",\n",
        "        \"description\": \"Get the next flight from delhi to mumbai\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"from\": {\"type\": \"string\"},\n",
        "                \"to\": {\"type\": \"string\"},\n",
        "                \"date\": {\"type\": \"string\"},\n",
        "            },\n",
        "            \"required\": [\"from\", \"to\", \"date\"],\n",
        "        },\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "MQO-w59ujrLu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}