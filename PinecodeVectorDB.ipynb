{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtMGTtfVQSCVKImHc2nMFG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rswijesena/AI/blob/main/PinecodeVectorDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector DB"
      ],
      "metadata": {
        "id": "qWN4l9pog7Vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install langchain\n",
        "#!pip install pinecone-client\n",
        "#!pip install openai\n",
        "#!pip install pypdf\n",
        "#!pip install tiktoken\n",
        "!pip install langchain-community"
      ],
      "metadata": {
        "id": "NzYNjTurhBs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet  langchain-pinecone langchain-openai langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4Swf2niM09Z",
        "outputId": "c5415cd3-251e-4248-e28a-82a2414393bb"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/215.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m215.0/215.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.9/215.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.vectorstores import Pinecone\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "import os\n"
      ],
      "metadata": {
        "id": "f3_BjkcIypAu"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir pdfs"
      ],
      "metadata": {
        "id": "swGW3vp10WrW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFDirectoryLoader(\"pdfs\")"
      ],
      "metadata": {
        "id": "jZkei_X93YvW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = loader.load()"
      ],
      "metadata": {
        "id": "FPX-ej8U36W3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "id": "pVW3iy7l3-mO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)"
      ],
      "metadata": {
        "id": "KfnIESvK4zc_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks = text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "VHV-LviU7I80"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_chunks[1].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQLIMmmt7O4R",
        "outputId": "e9b7739d-694f-4d19-b87a-468b3113f36e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "431"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"---\"\n",
        "\n",
        "os.environ[\"PINECONE_API_KEY\"] = \"---\""
      ],
      "metadata": {
        "id": "tNsGKS6T8XvI"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "8X1uUsXe9lfl"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.embed_query(\"How are you?\")"
      ],
      "metadata": {
        "id": "TeiQEMvo9nvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore"
      ],
      "metadata": {
        "id": "oSzMVx4WDObo"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"firstvector\"\n",
        "docsearch = PineconeVectorStore.from_documents(text_chunks, embeddings, index_name=index_name)\n"
      ],
      "metadata": {
        "id": "pmncuUftIRz-"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch.as_retriever()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-C0fb0TZfzr",
        "outputId": "e88a3c7f-9f96-4bb0-fc47-42195d9097d1"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['PineconeVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x7c9596b62f80>)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is Scaled Dot-Product Attention?\""
      ],
      "metadata": {
        "id": "ZMvw89XsT1NU"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = docsearch.similarity_search(query)"
      ],
      "metadata": {
        "id": "kpG2VXkjUQeI"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSNQjqlsUXFA",
        "outputId": "5ddbab1f-f037-4cdc-e2da-55ad6a4e076a"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Decoder: The decoder is also composed of a stack of N= 6identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This', metadata={'page': 2.0, 'source': 'pdfs/allyouneed.pdf'})"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "IK1aBTRKVBbN"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
      ],
      "metadata": {
        "id": "u-hZU2jOVE9e"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "LpV0o8tcVTmm",
        "outputId": "686b30b4-fa6d-45ab-d394-f1be6890138c"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Scaled Dot-Product Attention is a type of attention mechanism used in neural networks, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key. It is called \"scaled\" because the dot products are scaled by a factor of 1/sqrt(dk) to prevent extremely large gradients.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "while True:\n",
        "  user_input = input(f\"Input Prompt:\" )\n",
        "  if user_input == \"exit\":\n",
        "    sys.exit()\n",
        "  if user_input == '':\n",
        "    continue\n",
        "  result = qa.run({'query': user_input})\n",
        "  print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "84FQdHGrZrdm",
        "outputId": "34cc8f44-584f-45f5-b957-76d9f1a18acf"
      },
      "execution_count": 97,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Prompt:who is Jimmy Lei Ba?\n",
            " I don't know.\n",
            "Input Prompt:what did who is Jimmy Lei Ba do?\n",
            " I don't know.\n",
            "Input Prompt:what Jimmy Lei Ba done?\n",
            " I don't know.\n",
            "Input Prompt:any acknowledgements?\n",
            " Yes, the acknowledgements are listed in the context provided. They include Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, and Aidan N. Gomez.\n",
            "Input Prompt:is the code available somewhere?\n",
            " Yes, the code used to train and evaluate the models is available at https://github.com/tensorflow/tensor2tensor.\n",
            "Input Prompt:exit\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    }
  ]
}